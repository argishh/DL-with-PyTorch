{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Evaluation Metrics for Text Generation**\n",
    "\n",
    "Aim: Text generation model aims to generate human-like text\n",
    "\n",
    "Standard Accuracy Metrics like Accuracy and F1 Score falls short for these tasks.\n",
    "\n",
    "Therefore, we use metrics like -\n",
    "- BLEU (Bilingual Evaluation Understudy)\n",
    "- ROUGE (Recall-Oriented Understudy for Gisting Evaluation)\n",
    "\n",
    "#### **BLEU**\n",
    "\n",
    "It compares the generated text and the reference text, and checks for the occurrence of n-grams.\n",
    "\n",
    "In the sentence \"The Cat is on the mat\", \n",
    "- 1-grams (uni-gram) are [`the`, `cat`, `is`, `on`, `the`, `mat`]\n",
    "- 2-grams (bi-gram) are [`the cat`, `cat is`, `is on`, `on the`, `the mat`]\n",
    "- and so on... for n-grams\n",
    "\n",
    "In BLEU, a perfect match yields a score of `1.0` \\\n",
    "While a score of `0` means no match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 0.7598\n"
     ]
    }
   ],
   "source": [
    "# BLEU score with PyTorch\n",
    "\n",
    "from torchmetrics.text import BLEUScore\n",
    "\n",
    "generated_text = ['the cat is on the mat']\n",
    "real_text = [['there is a cat on the mat', 'a cat is on the mat']]\n",
    "\n",
    "bleu = BLEUScore()\n",
    "bleu_metric = bleu(generated_text, real_text)\n",
    "print(f'BLEU Score: {bleu_metric.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **ROUGE**\n",
    "\n",
    "It compares a generated text to a reference text in two ways -\n",
    "- `ROUGE-N`: Considers overlapping n-grams (N=1 for unigrams, 2 for bigrams, etc.) in both texts.\n",
    "- `ROUGE-L`: Looks at the longest common subsequence (LCS) between the texts.\n",
    "\n",
    "ROUGE Metrics -\n",
    "- F-Measure: Harmonic mean\n",
    "- Precision: Matches the n-grams in generated text within the reference text\n",
    "- Recall: Matches of n-grams in reference text within the generated text\n",
    "\n",
    "`rouge1`, `rouge2`, `rougeL` prefixes refer to 1-gram, 2-gram or LCS, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE Score: {'rouge1_fmeasure': tensor(0.8889), 'rouge1_precision': tensor(0.8000), 'rouge1_recall': tensor(1.), 'rouge2_fmeasure': tensor(0.8571), 'rouge2_precision': tensor(0.7500), 'rouge2_recall': tensor(1.), 'rougeL_fmeasure': tensor(0.8889), 'rougeL_precision': tensor(0.8000), 'rougeL_recall': tensor(1.), 'rougeLsum_fmeasure': tensor(0.8889), 'rougeLsum_precision': tensor(0.8000), 'rougeLsum_recall': tensor(1.)}\n"
     ]
    }
   ],
   "source": [
    "from torchmetrics.text import ROUGEScore\n",
    "\n",
    "generated_text = 'Hello, how are you doing?'\n",
    "real_text = \"Hello, how are you?\"\n",
    "\n",
    "rouge = ROUGEScore()\n",
    "\n",
    "rouge_score = rouge([generated_text], [[real_text]])\n",
    "print(f\"ROUGE Score: {rouge_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Limitations of BLEU and ROUGE**\n",
    "\n",
    "- They evaluate word presence, without considering its semantic meaninng.\n",
    "- They are sensitive to the length of the generated text.\n",
    "- The quality of reference text affects the scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
