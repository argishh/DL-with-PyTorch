{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Text Generation and NLP**\n",
    "\n",
    "Applications -\n",
    "- Chatbots\n",
    "- Langugae Translation\n",
    "- Technical Writing\n",
    "\n",
    "Suggested models - \n",
    "- RNN\n",
    "- LSTM\n",
    "- GRU\n",
    "\n",
    "The above mentioned mdoels are good at remembering past information for better sequential data processing. \\\n",
    "Better architectures exists, like GPT, BERT, etc. which are based on Transformers architecture and attention mechanisms, and are much more advanced than RNN based models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Using RNN for Text Generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(1, x.size(0), self.hidden_size)\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'Hello how are you?'\n",
    "chars = list(set(data))\n",
    "char_to_idx = {char: i for i, char in enumerate(chars)}\n",
    "idx_to_char = {i: char for i, char in enumerate(chars)}\n",
    "\n",
    "model = RNNModel(len(chars), 16, len(chars))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [char_to_idx[ch] for ch in data[:-1]]\n",
    "targets = [char_to_idx[ch] for ch in data[1:]]\n",
    "\n",
    "inputs = torch.tensor(inputs, dtype=torch.long).view(-1, 1)\n",
    "inputs = nn.functional.one_hot(inputs, num_classes=len(chars)).float()\n",
    "\n",
    "targets = torch.tensor(targets, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100, Loss: 0.5637306571006775\n",
      "Epoch 20/100, Loss: 0.5619089007377625\n",
      "Epoch 30/100, Loss: 0.5605061054229736\n",
      "Epoch 40/100, Loss: 0.5593850016593933\n",
      "Epoch 50/100, Loss: 0.5584665536880493\n",
      "Epoch 60/100, Loss: 0.557700514793396\n",
      "Epoch 70/100, Loss: 0.5570527911186218\n",
      "Epoch 80/100, Loss: 0.5564987659454346\n",
      "Epoch 90/100, Loss: 0.5560205578804016\n",
      "Epoch 100/100, Loss: 0.5556041598320007\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch {epoch+1}/100, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Input: e, Predicted Character: l\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Switch to evaluation mode\n",
    "test_in = 'e'\n",
    "test_input = char_to_idx[test_in]\n",
    "test_input = nn.functional.one_hot(torch.tensor(test_input).view(-1, 1), num_classes=len(chars)).float()\n",
    "\n",
    "predicted_output = model(test_input)\n",
    "predicted_char_idx = torch.argmax(predicted_output, 1).item()\n",
    "predicted_char = idx_to_char[predicted_char_idx]\n",
    "\n",
    "print(f'Test Input: {test_in}, Predicted Character: {predicted_char}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
